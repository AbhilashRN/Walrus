{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc\n",
    "\n",
    "This module of the system provides the change in emotions of the movie as it progresses. The change is measured against every scene of the movie. Using The NLU APIs provided by IBM Watson, the emotion of each scene from the script of the movie is analysed. Then a plot is produced that describes the trend in the common emotions per scene. This is now compared with every script of movies from the available scripts. A correlation coeffecient is found for each emotion between the original movie and each of the other movies. The movie with the maximum correlation yeilds the movie that is likely most similar to the original movie.<br>\n",
    "\n",
    "##### Input\n",
    "\n",
    "Movie1, and emotion to be described(optional)\n",
    "\n",
    "##### Output\n",
    "\n",
    "Movie, that is most likely similar to Movie1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "  import Features, EntitiesOptions, KeywordsOptions, EmotionOptions\n",
    "\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "  username='06320980-d791-4920-834b-3c5368522608',\n",
    "  password='UKVXqFnwnNnZ',\n",
    "  version='2018-03-16')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'ascii'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "dic['Haider.pdf'] = 'CUT TO'\n",
    "dic['Highway.pdf'] = 'Sc # '\n",
    "dic['JabWeMet.pdf'] = 'Sc # '\n",
    "dic['Kaminey.pdf'] = 'CUT TO'\n",
    "dic['Maqbool.pdf'] = 'SC. '\n",
    "dic['Masaan.pdf'] = 'CUT TO'\n",
    "dic['NEERJA.pdf'] = 'CUT TO'\n",
    "dic['Pink.pdf'] = 'CUT TO'\n",
    "dic['Queen.pdf'] = 'CUT TO'\n",
    "dic['Raman Raghav 2_0.pdf'] = 'CUT TO'\n",
    "dic['Rang De Basanti Script - Film Companion-min.pdf'] = 'CUT TO'\n",
    "dic['Rockstar.pdf'] = 'Sc # '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movienames = ['Haider.pdf', 'Highway.pdf', 'JabWeMet.pdf', 'Kaminey.pdf', 'Maqbool.pdf', 'Masaan.pdf', 'NEERJA.pdf', 'Pink.pdf', 'Queen.pdf', 'Raman Raghav 2_0.pdf', 'Rang De Basanti Script - Film Companion-min.pdf', 'Rockstar.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotionRelater(x,y):\n",
    "    range=min(len(x), len(y))\n",
    "    #We can downsample too if required\n",
    "    arr = []\n",
    "    for index, emotionname in enumerate(emotions):\n",
    "        x1 = x[emotionname]\n",
    "        x2 = y[emotionname]\n",
    "        x1=x1[1:range]\n",
    "        x2=x2[1:range]\n",
    "        relation=np.corrcoef(x1,x2)\n",
    "        relativeIndex=relation[1][0]\n",
    "        #print(relativeIndex)\n",
    "        arr.append(relativeIndex)\n",
    "        \n",
    "    return np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class movie_df():\n",
    "    def __init__(self, moviename1):\n",
    "        self.movie_dataframe1 = pd.read_csv('../ScriptsDF/'+moviename1+'.csv')\n",
    "\n",
    "    def return_dataframe(self):\n",
    "        return self.movie_dataframe1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_similar(movie_dataframe1):\n",
    "    arr = {}\n",
    "    for moviename in movienames:\n",
    "        if moviename == moviename1:\n",
    "            continue\n",
    "        else:\n",
    "            movie2 = movie_df(moviename)\n",
    "            movie_dataframe2 = movie2.return_dataframe()\n",
    "        arr[moviename] = emotionRelater(movie_dataframe1,movie_dataframe2)\n",
    "\n",
    "\n",
    "    return max(arr, key = arr.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JabWeMet.pdf\n"
     ]
    }
   ],
   "source": [
    "moviename1 = 'Highway.pdf'\n",
    "movie1 = movie_df(moviename1)\n",
    "movie_dataframe1 = movie1.return_dataframe()\n",
    "print(recommend_similar(movie_dataframe1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To create dataframe and save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scene_by_scene():\n",
    "    def __init__(self, moviename):\n",
    "        self.moviename = moviename\n",
    "        path = '../Bollywood-Data-master/scripts-data/' + moviename\n",
    "        text = convert_pdf_to_txt(path)\n",
    "        delimiter = dic[moviename]\n",
    "        text2 = text.split(delimiter)\n",
    "        self.main_table = pd.DataFrame()\n",
    "        for i,txt in enumerate(text2):\n",
    "            try:\n",
    "                response = natural_language_understanding.analyze(\n",
    "                  text = txt,\n",
    "                  features=Features(\n",
    "                    emotion=EmotionOptions())).get_result()\n",
    "                mbst = response['emotion']['document']['emotion']\n",
    "                mbst['scene'] = i\n",
    "                table1 = pd.DataFrame.from_dict(mbst, orient='index').squeeze()\n",
    "\n",
    "                self.main_table = self.main_table.append(table1)\n",
    "            except:\n",
    "                self.main_table = self.main_table.append({'anger':0, 'disgust':0,'fear':0, 'joy':0,'sadness':0, 'scene':i}, ignore_index=True)\n",
    "        self.main_table['scene'] = self.main_table['scene'].astype(int)\n",
    "        self.main_table = self.main_table.set_index('scene')\n",
    "\n",
    "    def plot_emotion(self, emotion = ['anger', 'disgust','fear', 'joy','sadness']):\n",
    "        return self.main_table[emotion].plot(figsize = (20,15))\n",
    "    \n",
    "    def ret_dataframe(self):\n",
    "        return self.main_table\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfolder= '../ScriptsDF/'\n",
    "\n",
    "for moviename in movienames:\n",
    "    x = scene_by_scene(moviename)\n",
    "    df = x.ret_dataframe()\n",
    "    path = parfolder+moviename+'.csv'\n",
    "    df.to_csv(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataframe1 = x.ret_dataframe()\n",
    "movie_dataframe2 = y.ret_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotionRelater(movie_dataframe1,movie_dataframe2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
